{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reproducao-bert-artigo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwHurPrcu7Cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "fd5bc4a4-9cfd-4d9b-e0ce-c9d59adb0b57"
      },
      "source": [
        "# este script tenta reproducir os resultados do artigo \"BERT for Stock Market Sentiment Analysis\" do \n",
        "# autoria deles.\n",
        "\n",
        "# autor deste codigo: steve\n",
        "\n",
        "# notas: verificar que o Runtime do Colab seja GPU e Python 3.\n",
        "\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# clonamos o git\n",
        "!test -d bert_repo || git clone https://github.com/stonescenter/bert.git bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ: \n",
        "  print('Not connected to TPU') \n",
        "else: \n",
        "  print(\"Connected to TPU, please use GPU\")\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 465 (delta 1), reused 3 (delta 0), pack-reused 457\n",
            "Receiving objects: 100% (465/465), 700.59 KiB | 6.87 MiB/s, done.\n",
            "Resolving deltas: 100% (265/265), done.\n",
            "Not connected to TPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k285wkrA1tD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "BERT_BASE_DIR='gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12'\n",
        "\n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'  \n",
        "#BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "\n",
        "# configuramos o modelo pre-treinado do bert\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL \n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "BERT_BASE_DIR = BERT_PRETRAINED_DIR\n",
        "!gsutil ls $BERT_BASE_DIR\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KreT_7IQONSA",
        "colab_type": "code",
        "outputId": "4b210875-25f0-4b4c-b2dd-ebc6b24fb8ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# dados temporales durante a session em colab\n",
        "DATA_TRAIN ='bert_repo/BNEWS_DATA/datasetEconomyNews_PN.json'\n",
        "DATA_TEST = 'bert_repo/BNEWS_DATA/predict_data.json'\n",
        "\n",
        "TASK_NAME = 'bnd'\n",
        "\n",
        "# bucket propio para almacenar se nao tem entao sera eliminado constantemente\n",
        "# em cada sesion\n",
        "#BUCKET = 'hd-storage-bucket'\n",
        "#OUTPUT_DIR = 'gs://{}/bert/models/{}'.format(BUCKET, TASK_NAME)\n",
        "\n",
        "OUTPUT_DIR = 'output/bert/{}'.format(TASK_NAME)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Directorio creado : {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "#!gsutil ls -la $OUTPUT_DIR\n",
        "!test -d $OUTPUT_DIR\n",
        "if not OUTPUT_DIR in sys.path:\n",
        "  sys.path += [OUTPUT_DIR]\n",
        "  \n",
        "#with tf.gfile.GFile(OUTPUT_DIR + '/dataDistribution.txt', 'a') as f:\n",
        "#  f.write(\"------ STATISTICS %s ------\\n\")\n",
        "#f.close()\n",
        "#!gsutil cat $DIST\n",
        "\n",
        "#comando para editar un file\n",
        "#%pycat bert_repo/run_classifier.py\n",
        "#!rm bert_repo/run_classifier.py\n",
        "#%%writefile bert_repo/run_classifier.py\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Directorio creado : output/bert/bnd *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5vNQ_athkNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verificamos se funciona a variavel DATA_TEST dados do teste\n",
        "data_predict = []\n",
        "with tf.gfile.Open(DATA_TEST,'r') as fp:\n",
        "  data_predict = json.load(fp)\n",
        "\n",
        "for block in data_predict:\n",
        "  title, text =  block[\"headlineTitle\"], block[\"headlineText\"]\n",
        "  print(text)\n",
        "print(DATA_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RCAB7tjMDND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mandamos a treinar os dados.\n",
        "!python bert_repo/run_classifier.py \\\n",
        "--task_name=$TASK_NAME \\\n",
        "--do_train=true \\\n",
        "--do_eval=true \\\n",
        "--do_test=true \\\n",
        "--do_predict=true \\\n",
        "--data_dir=$DATA_TRAIN \\\n",
        "--vocab_file=$BERT_BASE_DIR/vocab.txt \\\n",
        "--bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n",
        "--init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n",
        "--max_seq_length=64 \\\n",
        "--train_batch_size=32 \\\n",
        "--learning_rate=2e-5 \\\n",
        "--num_train_epochs=10.0 \\\n",
        "--output_dir=$OUTPUT_DIR \\\n",
        "--seed=123124124"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEoqHuQOBIxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mandamos a testar os dados.  Aqui sai um error de incompatibilidade, o motivo parecer ser o tensorflow e os checkpoint\n",
        "# e nao ao codigo.\n",
        "!python bert_repo/run_classifier.py \\\n",
        "--task_name=$TASK_NAME \\\n",
        "--do_predict=true \\\n",
        "--data_dir=$DATA_TEST \\\n",
        "--vocab_file=$BERT_BASE_DIR/vocab.txt \\\n",
        "--bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n",
        "--init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n",
        "--max_seq_length=64 \\\n",
        "--output_dir=$OUTPUT_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUL_2mkLgacx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}